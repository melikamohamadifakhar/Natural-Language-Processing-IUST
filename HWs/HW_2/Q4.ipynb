{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Li6hCkU3W60"
      },
      "source": [
        "1.Submit a Google Colab notebook containing your completed code and experimentation results.\n",
        "\n",
        "2.Include comments and explanations in your code to help understand the implemented logic.\n",
        "\n",
        "**Additional Notes:**\n",
        "*   Ensure that the notebook runs successfully in Google Colab.\n",
        "*   Document any issues encountered during experimentation and how you addressed them.\n",
        "\n",
        "**Grading:**\n",
        "*   Each task will be graded out of the specified points.\n",
        "*   Points will be awarded for correctness, clarity of code, thorough experimentation, and insightful analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoUu86p1Or1n"
      },
      "source": [
        "# Prediction-Based Word Vectors\n",
        "\n",
        "more recently prediction-based word vectors have demonstrated better performance, such as word2vec and GloVe (which also utilizes the benefit of counts). Here, we shall explore the embeddings produced by GloVe.\n",
        "\n",
        "Then run the following cells to load the GloVe vectors into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvpYg_7pODYJ",
        "outputId": "06b9ee62-a9b1-4618-9f6e-04bf6e5df858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 252.1/252.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "import pprint\n",
        "wv_from_bin = api.load(\"glove-wiki-gigaword-200\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFfCOLUsSSuS"
      },
      "source": [
        "### Words with Multiple Meanings\n",
        "Polysemes and homonyms are words that have more than one meaning (see this [wiki page](https://en.wikipedia.org/wiki/Polysemy) to learn more about the difference between polysemes and homonyms ). Find a word with *at least two different meanings* such that the top-10 most similar words (according to cosine similarity) contain related words from *both* meanings. For example, \"leaves\" has both \"go_away\" and \"a_structure_of_a_plant\" meaning in the top 10, and \"scoop\" has both \"handed_waffle_cone\" and \"lowdown\". You will probably need to try several polysemous or homonymic words before you find one.\n",
        "\n",
        "Please state the word you discover and the multiple meanings that occur in the top 10. Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain **one** of the meanings of the words)?\n",
        "\n",
        "**Note**: You should use the `wv_from_bin.most_similar(word)` function to get the top 10 similar words. This function ranks all other words in the vocabulary with respect to their cosine similarity to the given word. For further assistance, please check the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar)__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZAr09U-xSSuT"
      },
      "outputs": [],
      "source": [
        "### CODE HERE\n",
        "# Load the GloVe word vectors\n",
        "wv_from_bin = api.load(\"glove-wiki-gigaword-200\")\n",
        "\n",
        "word = 'bank'\n",
        "\n",
        "top_10_similar_words = wv_from_bin.most_similar(word, topn=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "word = 'novel'\n",
        "\n",
        "top_10_similar_words = wv_from_bin.most_similar(word, topn=10)\n",
        "top_10_similar_words"
      ],
      "metadata": {
        "id": "Adjf3FXsimDh",
        "outputId": "21847c76-4998-41f4-f6b6-781561b17d06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('novels', 0.7762995958328247),\n",
              " ('adaptation', 0.7534605264663696),\n",
              " ('book', 0.7485204935073853),\n",
              " ('fiction', 0.734031617641449),\n",
              " ('author', 0.7132314443588257),\n",
              " ('novelist', 0.6811251044273376),\n",
              " ('story', 0.677466869354248),\n",
              " ('memoir', 0.6494017243385315),\n",
              " ('novella', 0.6484362483024597),\n",
              " ('tale', 0.6375203132629395)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdQ018tjSSuT"
      },
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfeW-eK9SSuU"
      },
      "source": [
        "### Synonyms & Antonyms\n",
        "\n",
        "When considering Cosine Similarity, it's often more convenient to think of Cosine Distance, which is simply 1 - Cosine Similarity.\n",
        "\n",
        "Find three words $(w_1,w_2,w_3)$ where $w_1$ and $w_2$ are synonyms and $w_1$ and $w_3$ are antonyms, but Cosine Distance $(w_1,w_3) <$ Cosine Distance $(w_1,w_2)$.\n",
        "\n",
        "As an example, $w_1$=\"happy\" is closer to $w_3$=\"sad\" than to $w_2$=\"cheerful\". Please find a different example that satisfies the above. Once you have found your example, please give a possible explanation for why this counter-intuitive result may have happened.\n",
        "\n",
        "You should use the the `wv_from_bin.distance(w1, w2)` function here in order to compute the cosine distance between two words. Please see the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance)__ for further assistance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bwlpPjpHSSuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f5bc86-6aff-429c-b06e-57a8ced41796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms hot, warm have cosine distance: 0.4111672639846802\n",
            "Antonyms hot, cold have cosine distance: 0.40621882677078247\n"
          ]
        }
      ],
      "source": [
        "w1 = \"hot\"\n",
        "w2 = \"warm\"\n",
        "w3 = \"cold\"\n",
        "w1_w2_dist = wv_from_bin.distance(w1, w2)\n",
        "w1_w3_dist = wv_from_bin.distance(w1, w3)\n",
        "\n",
        "print(\"Synonyms {}, {} have cosine distance: {}\".format(w1, w2, w1_w2_dist))\n",
        "print(\"Antonyms {}, {} have cosine distance: {}\".format(w1, w3, w1_w3_dist))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIHjTFMSSuV"
      },
      "source": [
        "### SOLUTION\n",
        "**Analysis:** <br>\n",
        "In many semantic spaces, the word \"hot\" and its antonym \"cold\" might be closer together than \"hot\" and its synonym \"warm\" because \"cold\" is a more contrasting concept to \"hot\" than \"warm\" is. Cosine distance captures the angular difference between word vectors, and in some cases, this angular difference might be smaller between antonyms due to their contrasting nature, leading to a smaller cosine distance. Conversely, synonyms might have a larger cosine distance due to the subtle differences in their usage contexts, resulting in a larger angular difference between their word vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxIDq26zSSuW"
      },
      "source": [
        "### Analogies with Word Vectors\n",
        "Word vectors have been shown to *sometimes* exhibit the ability to solve analogies.\n",
        "\n",
        "As an example, for the analogy \"man : grandfather :: woman : x\" (read: man is to grandfather as woman is to x), what is x?\n",
        "\n",
        "In the cell below, we show you how to use word vectors to find x using the `most_similar` function from the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.most_similar)__. The function finds words that are most similar to the words in the `positive` list and most dissimilar from the words in the `negative` list. The answer to the analogy will have the highest cosine similarity (largest returned numerical value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u0pC7H4VSSuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70852006-f0d6-43b7-bcd4-e14338c2f236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('grandmother', 0.7608445286750793),\n",
            " ('granddaughter', 0.7200808525085449),\n",
            " ('daughter', 0.7168302536010742),\n",
            " ('mother', 0.7151536345481873),\n",
            " ('niece', 0.7005682587623596),\n",
            " ('father', 0.6659887433052063),\n",
            " ('aunt', 0.6623408794403076),\n",
            " ('grandson', 0.6618767976760864),\n",
            " ('grandparents', 0.644661009311676),\n",
            " ('wife', 0.6445354223251343)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to answer the analogy -- man : grandfather :: woman : x\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'grandfather'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVv8I9WwSSuZ"
      },
      "source": [
        "Let $m$, $g$, $w$, and $x$ denote the word vectors for `man`, `grandfather`, `woman`, and the answer, respectively. Using **only** vectors $m$, $g$, $w$, and the vector arithmetic operators $+$ and $-$ in your answer, to what expression are we maximizing $x$'s cosine similarity?\n",
        "\n",
        "Hint: Recall that word vectors are simply multi-dimensional vectors that represent a word. It might help to draw out a 2D example using arbitrary locations of each vector. Where would `man` and `woman` lie in the coordinate plane relative to `grandfather` and the answer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUKBqtHSSuZ"
      },
      "source": [
        "### SOLUTION\n",
        "In the analogy \"man : grandfather :: woman : x\", we're essentially looking for the word that is to \"woman\" as \"grandfather\" is to \"man\". Geometrically, this means finding the vector x such that: <br>x=w+(g−m)<br>\n",
        "\n",
        "This expression involves vector arithmetic: <br>\n",
        "g−m calculates the direction from \"man\" to \"grandfather\".\n",
        "<br>\n",
        "w+(g−m) moves from the position of \"woman\" in the direction from \"man\" to \"grandfather\".\n",
        "So, we're maximizing the cosine similarity of vector x to the result of adding the direction from \"man\" to \"grandfather\" to the vector representing \"woman\".\n",
        "\n",
        "This operation essentially involves shifting the vector representing \"woman\" along the same direction and magnitude as the vector from \"man\" to \"grandfather\". Geometrically, it's akin to translating the position of \"woman\" to a position that would be analogous to \"man\" becoming \"grandfather\". <br>\n",
        "clearer form of expression:\n",
        "\n",
        "x = woman + (grandfather − man)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRgMca9SSua"
      },
      "source": [
        "### Finding Analogies\n",
        "a. For the previous example, it's clear that \"grandmother\" completes the analogy. But give an intuitive explanation as to why the `most_similar` function gives us words like \"granddaughter\", \"daughter\", or \"mother?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgYQXazQSSua"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "1. Family Relationship: The word vectors for \"woman\" and \"man\" are likely to be close in the vector space because they represent similarly, \"grandfather\" and \"grandmother\" are close because they represent the same family relationship. When we subtract the vector for \"man\" from \"grandfather\", we get a direction vector that represents the concept of becoming a grandfather, which is likely to be almost orthogonal to the gender vector difference between \"woman\" and \"man\".\n",
        "\n",
        "2.  Proximity in Vector Space: Words like \"granddaughter\", \"daughter\", and \"mother\" are conceptually related to the concept of \"woman\" and \"grandfather\", albeit not exactly synonymous. They share semantic similarities because they represent familial relationships that are closely associated with the concept of \"grandfather\" and \"woman\". Therefore, they may appear among the most similar words due to their proximity in the vector space, even though \"grandmother\" might be the most direct completion of the analogy.\n",
        "\n",
        "3.  Frequency in Corpus: Additionally, the frequency of these words in the training corpus might also influence their cosine similarity scores. If \"granddaughter\", \"daughter\", or \"mother\" appear more frequently in contexts similar to \"woman\" and \"grandfather\" than \"grandmother\" does, they might receive higher similarity scores despite \"grandmother\" being a more direct completion of the analogy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9aAUXEISSub"
      },
      "source": [
        "b. Find an example of analogy that holds according to these vectors (i.e. the intended word is ranked top). In your solution please state the full analogy in the form x:y :: a:b. If you believe the analogy is complicated, explain why the analogy holds in one or two sentences.\n",
        "\n",
        "**Note**: You may have to try many analogies to find one that works!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dhzQJMYYVSjf"
      },
      "outputs": [],
      "source": [
        "x, y, a, b = \"king\", \"queen\", \"man\", \"woman\"\n",
        "assert wv_from_bin.most_similar(positive=[a, y], negative=[x])[0][0] == b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3QlPqAwSSub"
      },
      "source": [
        "### SOLUTION\n",
        "\"king : queen :: man : woman\"\n",
        "\n",
        "In this analogy, we expect the word that completes the analogy to be \"woman\" since \"queen\" is the female counterpart to \"king\" just as \"woman\" is the female counterpart to \"man\".\n",
        "\n",
        "This analogy holds because the word vectors capture the semantic relationship between \"king\" and \"queen\" as well as \"man\" and \"woman\", which are hierarchical and gender-specific. Therefore, the word \"woman\" is ranked top in the most_similar function output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwgcEywwSSuc"
      },
      "source": [
        "### Incorrect Analogy\n",
        "a. Below, we expect to see the intended analogy \"hand : glove :: foot : **sock**\", but we see an unexpected result instead. Give a potential reason as to why this particular analogy turned out the way it did?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "m-ykWoJoSSuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a81058d-3ac7-4942-fb59-e5ac4d4a9a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('45,000-square', 0.4922032654285431),\n",
            " ('15,000-square', 0.4649604558944702),\n",
            " ('10,000-square', 0.4544755816459656),\n",
            " ('6,000-square', 0.44975775480270386),\n",
            " ('3,500-square', 0.444133460521698),\n",
            " ('700-square', 0.44257497787475586),\n",
            " ('50,000-square', 0.4356396794319153),\n",
            " ('3,000-square', 0.43486514687538147),\n",
            " ('30,000-square', 0.4330596923828125),\n",
            " ('footed', 0.43236875534057617)]\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(wv_from_bin.most_similar(positive=['foot', 'glove'], negative=['hand']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn4ruS8MSSud"
      },
      "source": [
        "### SOLUTION\n",
        "why the best similarities might be numerical values rather than words?\n",
        "\n",
        "**Data Bias:** The training data could contain biases or patterns that are not intuitively related to the analogy but are statistically significant within the data. For instance, if the dataset contains a lot of real estate listings or descriptions where measurements and \"foot\" or \"square foot\" are frequently mentioned together, the model might learn to associate \"foot\" more strongly with square footage than with items worn on the foot.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Polysemy:** The word \"foot\" is polysemous; it has multiple meanings, including as a unit of measurement (as in \"square foot\") and as a part of the body. If the model's representation of \"foot\" leans more towards its usage as a unit of measurement rather than a body part due to the training data, the analogy will skew towards related concepts in that domain.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gHyZt0SSud"
      },
      "source": [
        "b. Find another example of analogy that does *not* hold according to these vectors. In your solution, state the intended analogy in the form x:y :: a:b, and state the **incorrect** value of b according to the word vectors (in the previous example, this would be **'45,000-square'**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "D_rlci42XQTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442901ab-e983-4cff-ebc4-4269100b93d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('books', 0.616112232208252),\n",
            " ('bookstore', 0.5795304775238037),\n",
            " ('bookshop', 0.5778532028198242),\n",
            " ('author', 0.5619520545005798),\n",
            " ('publishing', 0.5522783994674683),\n",
            " ('published', 0.5197589993476868),\n",
            " ('novel', 0.5005371570587158),\n",
            " ('publications', 0.49985089898109436),\n",
            " ('publisher', 0.49705472588539124),\n",
            " ('memoir', 0.4887678921222687)]\n"
          ]
        }
      ],
      "source": [
        "x, y, a, b = \"bread\" , \"bakery\" , \"book\" , \"library\"\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[a, y], negative=[x]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4x0EHjeSSue"
      },
      "source": [
        "### SOLUTION\n",
        "Just as bread is produced and sold in a bakery, books are available and stored in a library.\n",
        "\n",
        "Reason: The training data might have a stronger association between books and the concept of publishing or production than their storage or availability in libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvlycXN-SSuf"
      },
      "source": [
        "### Guided Analysis of Bias in Word Vectors\n",
        "\n",
        "It's important to be cognizant of the biases (gender, race, sexual orientation etc.) implicit in our word embeddings. Bias can be dangerous because it can reinforce stereotypes through applications that employ these models.\n",
        "\n",
        "Run the cell below, to examine (a) which terms are most similar to \"woman\" and \"profession\" and most dissimilar to \"man\", and (b) which terms are most similar to \"man\" and \"profession\" and most dissimilar to \"woman\". Point out the difference between the list of female-associated words and the list of male-associated words, and explain how it is reflecting gender bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XggWA4MhSSuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad3059a-2b01-455b-b81e-3e823baf4466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('reputation', 0.5250176787376404),\n",
            " ('professions', 0.5178037881851196),\n",
            " ('skill', 0.49046966433525085),\n",
            " ('skills', 0.49005505442619324),\n",
            " ('ethic', 0.4897659420967102),\n",
            " ('business', 0.4875852167606354),\n",
            " ('respected', 0.485920250415802),\n",
            " ('practice', 0.482104629278183),\n",
            " ('regarded', 0.4778572618961334),\n",
            " ('life', 0.4760662019252777)]\n",
            "\n",
            "[('professions', 0.5957457423210144),\n",
            " ('practitioner', 0.49884122610092163),\n",
            " ('teaching', 0.48292139172554016),\n",
            " ('nursing', 0.48211804032325745),\n",
            " ('vocation', 0.4788965880870819),\n",
            " ('teacher', 0.47160351276397705),\n",
            " ('practicing', 0.46937814354896545),\n",
            " ('educator', 0.46524327993392944),\n",
            " ('physicians', 0.4628995358943939),\n",
            " ('professionals', 0.4601394236087799)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell\n",
        "# Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be most dissimilar from.\n",
        "\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['man', 'profession'], negative=['woman']))\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'profession'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4g6KbsYSSuh"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "\n",
        "\n",
        "*   For men, the model listed qualities like being skilled, ethical, and respected, without pointing to specific jobs. It's like saying men are seen in a wide variety of important roles but not tying them down to any particular job.\n",
        "\n",
        "*   For women, the model pointed to specific jobs like teaching and nursing, which are often seen as caring or nurturing roles. It kind of boxed women into certain types of jobs traditionally thought of as \"women's work.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxJmnS6lSSui"
      },
      "source": [
        "### Independent Analysis of Bias in Word Vectors\n",
        "\n",
        "Use the `most_similar` function to find another pair of analogies that demonstrates some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PZoDheIfSSui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b76e247-a0f2-4ef4-8710-e6d12f7e144e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('principles', 0.4248402416706085),\n",
            " ('spirit', 0.4119269847869873),\n",
            " ('peacefully', 0.4070417582988739),\n",
            " ('sustainable', 0.4070028066635132),\n",
            " ('promote', 0.39793041348457336),\n",
            " ('harmony', 0.3913986384868622),\n",
            " ('coexistence', 0.3912509083747864),\n",
            " ('harmonious', 0.3873632252216339),\n",
            " ('unity', 0.3870052695274353),\n",
            " ('dialogue', 0.386999249458313)]\n",
            "\n",
            "[('peacefully', 0.5776247978210449),\n",
            " ('kashmir', 0.5749312043190002),\n",
            " ('kashmiris', 0.5432711243629456),\n",
            " ('iranians', 0.5095259547233582),\n",
            " ('muslims', 0.49575552344322205),\n",
            " ('moslem', 0.4929211735725403),\n",
            " ('demonstrations', 0.4893590211868286),\n",
            " ('protests', 0.48372882604599),\n",
            " ('musharraf', 0.47846537828445435),\n",
            " ('crackdown', 0.4762367904186249)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to answer the analogy -- man : grandfather :: woman : x\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'grandfather'], negative=['man']))\n",
        "x = woman + (grandfather − man)\n",
        "\n",
        "A = \"christian\"\n",
        "B = \"muslim\"\n",
        "word = \"peaceful\"\n",
        "\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[A, word], negative=[B])) # christian + (peaceful - muslim)\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[B, word], negative=[A])) # muslim + (peaceful - christian)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGOlmtJoSSuj"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "**Analysis of \"Christian + peaceful - Muslim\"** <br>\n",
        "The terms associated with \"Christian + peaceful - Muslim\" include \"principles,\" \"spirit,\" \"peacefully,\" \"sustainable,\" \"promote,\" \"harmony,\" \"coexistence,\" \"harmonious,\" \"unity,\" and \"dialogue.\" These words paint a picture of peace in abstract, idealistic terms, focusing on the positive aspects of peace like harmony, unity, and dialogue and suggesting an idealized view of peace associated with Christian contexts.\n",
        "\n",
        "\n",
        "**Analysis of \"Muslim + peaceful - Christian\"** <br>\n",
        "Conversely, the terms related to \"Muslim + peaceful - Christian\" are more specific and grounded in geopolitical realities, including \"peacefully,\" \"kashmir,\" \"kashmiris,\" \"iranians,\" \"muslims,\" \"moslem,\" \"demonstrations,\" \"protests,\" \"musharraf,\" and \"crackdown.\" This list reflects a direct association with specific regions and events, such as Kashmir and Iran, and suggests a narrative of struggle or conflict, with \"demonstrations,\" \"protests,\" and \"crackdown\" indicating societal unrest. Overall, the context is markedly different from the abstract principles associated with the Christian query.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK2XVWzmSSuk"
      },
      "source": [
        "### Thinking About Bias\n",
        "\n",
        "a. Give one explanation of how bias gets into the word vectors. Briefly describe a real-world example that demonstrates this source of bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19pM85fCSSuk"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "**Data-Driven Bias**\n",
        "\n",
        "Word vectors are generated by analyzing vast amounts of text data. If this data contains biased language or perspectives—like stereotypical roles, unequal representation of genders, races, ethnicities, or any other group—these biases are learned by the model.\n",
        "\n",
        "**Real-World Example:**\n",
        "\n",
        "Imagine we have a model that helps companies decide who to interview for jobs. This model is taught how to pick candidates by looking at old job ads and the resumes of people who got those jobs. If most of these old ads for engineering jobs talk about men or use words more often used when talking about men, the model starts to think that engineering jobs are mostly for men. And if ads for nursing jobs do the same for women, the model thinks nursing is mostly for women.\n",
        "\n",
        "Now, when this model looks at new applications, it might prefer men for engineering jobs and women for nursing jobs, not because it's trying to be unfair, but because that's what it learned from the old ads and resumes. This happened for real with some hiring models, making it harder for women to get considered for some tech jobs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILYqJZ7ASSul"
      },
      "source": [
        "b. What is one method you can use to mitigate bias exhibited by word vectors?  Briefly describe a real-world example that demonstrates this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJaAB7mSSul"
      },
      "source": [
        "\n",
        "### SOLUTION\n",
        "\n",
        "\n",
        "**Adversarial Training for Equalizing Word Representations:**\n",
        "\n",
        "Adversarial training involves training a model to simultaneously generate word embeddings while also training an adversary to predict sensitive attributes from these embeddings. The goal is to encourage the model to generate embeddings that do not contain information about the sensitive attributes, effectively equalizing the representations across different groups.\n",
        "\n",
        "**Real-World Example:**\n",
        "\n",
        "Consider a scenario where a machine learning model is trained to generate word embeddings using a dataset containing text data from various sources, including social media posts, news articles, and literature. To mitigate biases related to gender, the model is trained using an adversarial setup:\n",
        "\n",
        "Embedding Generation: The model learns to generate word embeddings from the input text data, aiming to capture semantic information while minimizing the influence of sensitive attributes like gender.\n",
        "\n",
        "Adversarial Training: Simultaneously, an adversary model is trained to predict the gender of individuals mentioned in the text based on the generated word embeddings. The adversary's objective is to correctly predict gender while the embedding model aims to generate embeddings that confuse the adversary.\n",
        "\n",
        "Equalization Objective: The embedding model is optimized using an objective function that penalizes the adversary's ability to predict gender from the embeddings. This encourages the embedding model to generate embeddings that are indistinguishable in terms of gender, effectively equalizing the representations across different gender groups.\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}